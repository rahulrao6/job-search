"""
ELITE Free LinkedIn Profile Search
Actually works - tested with real searches
Uses multiple strategies with proper fallbacks
"""

import re
import time
import random
from typing import List, Dict, Optional
from urllib.parse import quote, quote_plus, urlencode
import requests
from bs4 import BeautifulSoup

from src.models.person import Person, PersonCategory


class EliteFreeLinkedInSearch:
    """
    Elite free LinkedIn search using multiple proven strategies.
    
    Strategies (in order of preference):
    1. DuckDuckGo HTML (POST method - most reliable)
    2. Bing web search (less aggressive than Google)
    3. Startpage (Google proxy)
    4. Brave Search API (2000 free/month)
    5. You.com API (unlimited free tier)
    
    Each returns LinkedIn URLs + metadata from search snippets.
    """
    
    USER_AGENTS = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    ]
    
    def __init__(self):
        self.session = requests.Session()
        self._set_headers()
    
    def _set_headers(self):
        """Set realistic browser headers"""
        self.session.headers.update({
            'User-Agent': random.choice(self.USER_AGENTS),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def search_all(self, company: str, title: str = None, max_results: int = 50) -> List[Person]:
        """
        Search all sources and aggregate results.
        
        Args:
            company: Company name
            title: Job title (optional, makes search more specific)
            max_results: Maximum results to return
            
        Returns:
            List of Person objects with LinkedIn URLs
        """
        all_people = []
        seen_urls = set()
        
        print(f"\nðŸ” Elite LinkedIn Search: {company} {title or ''}")
        
        # Try each search engine
        search_methods = [
            ('DuckDuckGo', self._search_duckduckgo),
            ('Bing', self._search_bing),
            ('Startpage', self._search_startpage),
            ('Brave', self._search_brave),
            ('You.com', self._search_you_com),
        ]
        
        for name, method in search_methods:
            if len(all_people) >= max_results:
                break
            
            try:
                print(f"  â†’ {name}...")
                people = method(company, title)
                
                # Deduplicate by LinkedIn URL
                new_count = 0
                for person in people:
                    if person.linkedin_url and person.linkedin_url not in seen_urls:
                        seen_urls.add(person.linkedin_url)
                        all_people.append(person)
                        new_count += 1
                
                if new_count > 0:
                    print(f"    âœ“ Found {new_count} profiles")
                else:
                    print(f"    - No results")
                    
            except Exception as e:
                print(f"    âœ— Error: {str(e)[:60]}")
            
            # Respectful delay
            time.sleep(random.uniform(1.0, 2.0))
        
        print(f"\nâœ… Total: {len(all_people)} LinkedIn profiles")
        return all_people[:max_results]
    
    def _search_duckduckgo(self, company: str, title: str = None) -> List[Person]:
        """
        DuckDuckGo HTML search - PROPER implementation.
        Uses POST method which is more reliable than GET.
        """
        people = []
        
        # Build query
        query_parts = [f'site:linkedin.com/in/']
        query_parts.append(f'"{company}"')
        if title:
            # Add job-specific keywords
            title_keywords = title.split()[:2]  # First 2 words
            for keyword in title_keywords:
                query_parts.append(f'"{keyword}"')
        
        query = ' '.join(query_parts)
        
        # DuckDuckGo HTML endpoint
        url = "https://html.duckduckgo.com/html/"
        
        # POST data (required for DuckDuckGo)
        data = {
            'q': query,
            'b': '',  # Offset for pagination
            'kl': 'us-en',
            'df': '',  # Date filter (empty = any time)
        }
        
        try:
            # POST request (more reliable than GET)
            response = self.session.post(url, data=data, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Parse results - DuckDuckGo has specific structure
                for result_div in soup.find_all('div', class_='result'):
                    try:
                        # Get the main link
                        link = result_div.find('a', class_='result__a')
                        if not link:
                            continue
                        
                        url = link.get('href', '')
                        title_text = link.get_text(strip=True)
                        
                        # Must be LinkedIn profile
                        if 'linkedin.com/in/' not in url:
                            continue
                        
                        # Extract name from title
                        # Format: "Name - Job Title - Company - LinkedIn"
                        parts = title_text.split(' - ')
                        if len(parts) >= 2:
                            name = parts[0].strip()
                            job_title = parts[1].strip() if len(parts) > 1 else None
                            
                            # Skip if name is too generic
                            if len(name) < 3 or name.lower() in ['linkedin', 'profile', 'about']:
                                continue
                            
                            person = Person(
                                name=name,
                                title=job_title,
                                company=company,
                                linkedin_url=url,
                                source='duckduckgo',
                                confidence_score=0.8  # High confidence from DDG
                            )
                            people.append(person)
                            
                    except Exception:
                        continue  # Skip this result
                        
        except Exception as e:
            # Silent fail - will try other sources
            pass
        
        return people
    
    def _search_bing(self, company: str, title: str = None) -> List[Person]:
        """
        Bing web search - less aggressive blocking than Google.
        """
        people = []
        
        # Build query
        query = f'site:linkedin.com/in/ "{company}"'
        if title:
            query += f' "{title}"'
        
        url = "https://www.bing.com/search"
        params = {
            'q': query,
            'count': 50,  # Max results per page
            'first': 1,  # Start index
        }
        
        try:
            response = self.session.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Bing result structure
                for result in soup.find_all('li', class_='b_algo'):
                    try:
                        h2 = result.find('h2')
                        if not h2 or not h2.find('a'):
                            continue
                        
                        link = h2.find('a')
                        url = link.get('href', '')
                        title_text = h2.get_text(strip=True)
                        
                        if 'linkedin.com/in/' not in url:
                            continue
                        
                        # Extract name (before first dash or pipe)
                        name_match = re.match(r'^([^-|]+)', title_text)
                        if name_match:
                            name = name_match.group(1).strip()
                            
                            # Extract job title if present
                            job_title = None
                            title_match = re.search(r' - (.+?) -', title_text)
                            if title_match:
                                job_title = title_match.group(1).strip()
                            
                            if len(name) > 2:
                                person = Person(
                                    name=name,
                                    title=job_title,
                                    company=company,
                                    linkedin_url=url,
                                    source='bing',
                                    confidence_score=0.75
                                )
                                people.append(person)
                                
                    except Exception:
                        continue
                        
        except Exception:
            pass
        
        return people
    
    def _search_startpage(self, company: str, title: str = None) -> List[Person]:
        """
        Startpage - privacy-focused Google proxy.
        """
        people = []
        
        query = f'site:linkedin.com/in/ "{company}"'
        if title:
            query += f' "{title}"'
        
        url = "https://www.startpage.com/do/search"
        params = {
            'query': query,
            'cat': 'web',
            'language': 'english',
        }
        
        try:
            response = self.session.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Startpage result structure
                for result in soup.find_all('div', class_='w-gl__result'):
                    try:
                        link = result.find('a', class_='w-gl__result-url')
                        if not link:
                            continue
                        
                        url = link.get('href', '')
                        
                        # Get title
                        title_elem = result.find('h2', class_='w-gl__result-title')
                        if not title_elem:
                            continue
                        
                        title_text = title_elem.get_text(strip=True)
                        
                        if 'linkedin.com/in/' in url:
                            name = title_text.split(' - ')[0].strip()
                            
                            if len(name) > 2:
                                person = Person(
                                    name=name,
                                    title=None,  # Startpage doesn't always show
                                    company=company,
                                    linkedin_url=url,
                                    source='startpage',
                                    confidence_score=0.7
                                )
                                people.append(person)
                                
                    except Exception:
                        continue
                        
        except Exception:
            pass
        
        return people
    
    def _search_brave(self, company: str, title: str = None) -> List[Person]:
        """
        Brave Search API - 2000 free queries/month.
        """
        import os
        api_key = os.getenv('BRAVE_API_KEY')
        if not api_key:
            return []  # Skip if not configured
        
        people = []
        
        query = f'site:linkedin.com/in/ "{company}"'
        if title:
            query += f' "{title}"'
        
        url = "https://api.search.brave.com/res/v1/web/search"
        headers = {
            'Accept': 'application/json',
            'Accept-Encoding': 'gzip',
            'X-Subscription-Token': api_key,
        }
        params = {
            'q': query,
            'count': 20,
        }
        
        try:
            response = requests.get(url, headers=headers, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                for result in data.get('web', {}).get('results', []):
                    url = result.get('url', '')
                    title_text = result.get('title', '')
                    
                    if 'linkedin.com/in/' in url:
                        name = title_text.split(' - ')[0].strip()
                        
                        if len(name) > 2:
                            person = Person(
                                name=name,
                                title=None,
                                company=company,
                                linkedin_url=url,
                                source='brave',
                                confidence_score=0.75
                            )
                            people.append(person)
                            
        except Exception:
            pass
        
        return people
    
    def _search_you_com(self, company: str, title: str = None) -> List[Person]:
        """
        You.com API - free unlimited tier.
        """
        import os
        api_key = os.getenv('YOU_COM_API_KEY')
        if not api_key:
            return []  # Skip if not configured
        
        people = []
        
        query = f'site:linkedin.com/in/ "{company}"'
        if title:
            query += f' "{title}"'
        
        url = "https://api.you.com/search"
        headers = {
            'X-API-Key': api_key,
        }
        params = {
            'query': query,
        }
        
        try:
            response = requests.get(url, headers=headers, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                for result in data.get('hits', []):
                    url = result.get('url', '')
                    title_text = result.get('title', '')
                    
                    if 'linkedin.com/in/' in url:
                        name = title_text.split(' - ')[0].strip()
                        
                        if len(name) > 2:
                            person = Person(
                                name=name,
                                title=None,
                                company=company,
                                linkedin_url=url,
                                source='you_com',
                                confidence_score=0.7
                            )
                            people.append(person)
                            
        except Exception:
            pass
        
        return people


def test_elite_search():
    """Test with real companies"""
    searcher = EliteFreeLinkedInSearch()
    
    test_cases = [
        ("Google", "Software Engineer"),
        ("Stripe", "Product Manager"),
        ("Cursor", None),
    ]
    
    for company, title in test_cases:
        print(f"\n{'='*60}")
        print(f"Testing: {company} - {title or 'Any'}")
        print('='*60)
        
        people = searcher.search_all(company, title, max_results=30)
        
        print(f"\nResults:")
        for i, person in enumerate(people[:5], 1):
            print(f"{i}. {person.name}")
            if person.title:
                print(f"   Title: {person.title}")
            print(f"   LinkedIn: {person.linkedin_url[:60]}...")
            print(f"   Source: {person.source}")
            print()


if __name__ == "__main__":
    test_elite_search()
